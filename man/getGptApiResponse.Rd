% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/getGptResponse.R
\name{getGptApiResponse}
\alias{getGptApiResponse}
\title{Request a GPT API Chat Completion or Responses API result}
\usage{
getGptApiResponse(
  token,
  base.url,
  model,
  api.type = c("completions", "responses"),
  messages = NULL,
  prompt = NULL,
  prompt.id = NULL,
  tools = NULL,
  max.tokens = 1024,
  temperature = NULL,
  stream = FALSE,
  top.p = 1,
  frequency.penalty = 0,
  presence.penalty = 0,
  stop = NULL,
  timeout = 60
)
}
\arguments{
\item{token}{Character. API token for authentication (required).}

\item{base.url}{Character. Base URL of the API endpoint (e.g., "https://api.openai.com").}

\item{model}{Character. Model identifier to use (e.g., "gpt-4o").}

\item{api.type}{Character. API type to use: "completions" or "responses".}

\item{messages}{List. Conversation history for completions API (list of lists with role/content).}

\item{prompt}{Character. Prompt text for responses API.}

\item{prompt.id}{Character. Unique ID for the prompt (responses API).}

\item{tools}{Character vector. Tools to enable for responses API (e.g., c("web_search")).}

\item{max.tokens}{Integer. Max tokens to generate (default: 1024).}

\item{temperature}{Numeric. Sampling temperature (default: 1 for completions, 0.7 for responses).}

\item{stream}{Logical. Stream partial responses (default: FALSE, completions only).}

\item{top.p}{Numeric. Nucleus sampling parameter (default: 1).}

\item{frequency.penalty}{Numeric. Frequency penalty (default: 0).}

\item{presence.penalty}{Numeric. Presence penalty (default: 0).}

\item{stop}{Character vector. Stop sequences for completions API.}

\item{timeout}{Numeric. Request timeout in seconds (default: 60).}
}
\value{
Parsed API response as list.
}
\description{
Sends a request to the specified OpenAI API (Chat Completions or Responses API) and returns the parsed response.
}
